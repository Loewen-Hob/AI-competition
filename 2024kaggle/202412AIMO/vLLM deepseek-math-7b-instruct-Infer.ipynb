{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86023,"databundleVersionId":9869096,"sourceType":"competition"},{"sourceId":8218776,"sourceType":"datasetVersion","datasetId":4871830},{"sourceId":8300737,"sourceType":"datasetVersion","datasetId":4746046},{"sourceId":41850,"sourceType":"modelInstanceVersion","modelInstanceId":35171,"modelId":49476}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\nI used the following great notebook as a reference.\n\n[Infer 34B with vLLM](https://www.kaggle.com/code/cdeotte/infer-34b-with-vllm) (by [Chris Deotte](https://www.kaggle.com/cdeotte))\n\n[vllm](https://github.com/vllm-project/vllm) is very fast inference!!!\n\nInference of the test data took about 30 minutes!!(GPU T4×2)\n\n(2024/10/26 update!) Inference of the test data took about 15 minutes!!(GPU L4×4)\n\nThe model is [deepseek-math-7b-instruct](https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct), which was strong in [AIMO1](https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize).","metadata":{}},{"cell_type":"markdown","source":"# Question\nPlease Comment.\n\nQ1. When I used GPU L4×4, I got an error when loading vllm.\n\n> The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n\n(2024/10/19)\n\nA1. This can be solved via setting swap_space=2 . As per the docs its the space in GB thats allocated in CPU per every available GPU. Since we have allowed 30 gb ram only, it gets a OOM error.\n\nThank you, [pjmathematician](https://www.kaggle.com/pjmathematician).","metadata":{}},{"cell_type":"markdown","source":"# Comment\nI do not do prompt engineering.\nprompt engineering alone would improve score.\n\nThe results generated by LLMs are currently processed in a messy.(There is much room for improvement!)\n\nThe solution method of the previous competition was very unique and even generated a program to solve the problem and execute it.\n\nReasoning with vllm is the basic library of this competition.\n\nLet's enjoy the competition together!\n\n\nTo be updated!! (I plan to add more hints if the number of votes increases.)","metadata":{}},{"cell_type":"code","source":"import os\nimport polars as pl\nimport kaggle_evaluation.aimo_2_inference_server","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:01:53.68762Z","iopub.execute_input":"2024-10-26T13:01:53.687909Z","iopub.status.idle":"2024-10-26T13:01:55.281378Z","shell.execute_reply.started":"2024-10-26T13:01:53.687875Z","shell.execute_reply":"2024-10-26T13:01:55.280586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" # \"0,1,2,3\"","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:01:55.28276Z","iopub.execute_input":"2024-10-26T13:01:55.283122Z","iopub.status.idle":"2024-10-26T13:01:55.286703Z","shell.execute_reply.started":"2024-10-26T13:01:55.283092Z","shell.execute_reply":"2024-10-26T13:01:55.286041Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n!pip uninstall -y torch\n!pip install -U --no-index --find-links=/kaggle/input/vllm-whl -U vllm\n!pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:01:55.28749Z","iopub.execute_input":"2024-10-26T13:01:55.287751Z","iopub.status.idle":"2024-10-26T13:04:52.567725Z","shell.execute_reply.started":"2024-10-26T13:01:55.287724Z","shell.execute_reply":"2024-10-26T13:04:52.566658Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nimport math\nfrom glob import glob\nfrom pathlib import Path\nimport joblib\nimport pickle\nimport itertools\nfrom tqdm.auto import tqdm\nimport re\n\nimport vllm","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:04:52.569829Z","iopub.execute_input":"2024-10-26T13:04:52.570125Z","iopub.status.idle":"2024-10-26T13:04:56.258245Z","shell.execute_reply.started":"2024-10-26T13:04:52.570094Z","shell.execute_reply":"2024-10-26T13:04:56.257505Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm = vllm.LLM(\n    \"/kaggle/input/deepseek-math-7b-instruct/transformers/main/1\", # \"deepseek-ai/deepseek-math-7b-instruct\"\n    tensor_parallel_size=4, # 2, 4 \n    gpu_memory_utilization=0.95, \n    trust_remote_code=True,\n    dtype=\"half\", \n    enforce_eager=True,\n    swap_space=2, # L4×4\n)\ntokenizer = llm.get_tokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:04:56.259173Z","iopub.execute_input":"2024-10-26T13:04:56.259592Z","iopub.status.idle":"2024-10-26T13:05:52.166055Z","shell.execute_reply.started":"2024-10-26T13:04:56.259562Z","shell.execute_reply":"2024-10-26T13:05:52.165126Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_text_vllm(requests, tokenizer, model):\n    sampling_params = vllm.SamplingParams(\n        temperature=0.00,\n        seed=42, \n        max_tokens=1024\n    )\n    responses = model.generate(requests, sampling_params=sampling_params, use_tqdm=False)\n    response_text_list = []\n    for response in responses:\n        # total_tokens += len(response.outputs[0].token_ids)\n        response_text_list.append(response.outputs[0].text)\n    return response_text_list","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:05:52.167116Z","iopub.execute_input":"2024-10-26T13:05:52.168089Z","iopub.status.idle":"2024-10-26T13:05:52.172689Z","shell.execute_reply.started":"2024-10-26T13:05:52.168054Z","shell.execute_reply":"2024-10-26T13:05:52.171889Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def naive_parse(answer):\n    out = []\n    start = False\n    end = False\n    for l in reversed(list(answer)):\n        if l in '0123456789' and not end:\n            start = True\n            out.append(l)\n        else:\n            if start:\n                end = True\n        \n    out = reversed(out)\n    return ''.join(out)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:05:52.173506Z","iopub.execute_input":"2024-10-26T13:05:52.173769Z","iopub.status.idle":"2024-10-26T13:05:52.183838Z","shell.execute_reply.started":"2024-10-26T13:05:52.173742Z","shell.execute_reply":"2024-10-26T13:05:52.183127Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tool_instruction = '\\nPlease solve the problem above, and put your final answer within \\\\boxed{}.'","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:05:52.184604Z","iopub.execute_input":"2024-10-26T13:05:52.184864Z","iopub.status.idle":"2024-10-26T13:05:52.191954Z","shell.execute_reply.started":"2024-10-26T13:05:52.184838Z","shell.execute_reply":"2024-10-26T13:05:52.191277Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace this function with your inference code.\n# The function should return a single integer between 0 and 999, inclusive.\n# Each prediction (except the very first) must be returned within 30 minutes of the question being provided.\ndef predict(id_: pl.Series, question: pl.Series) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # print(id_, question)\n    # print(type(id_), type(question))\n    id_ = id_.item(0)\n    question = question.item(0)\n    # print(id_, question)\n    # print(type(id_), type(question))\n    prompt = question + tool_instruction\n    generate_text = generate_text_vllm([prompt], tokenizer, llm)[0]\n    answer = 3\n    try:\n        result_output = re.findall(r'\\\\boxed\\{(\\d+)\\}', generate_text)\n        if len(result_output) > 0:\n            no = naive_parse(result_output[0])\n            if len(no) > 0:\n                answer = int(no) % 1000\n        print(answer)\n    except:\n        print('error')\n    return pl.DataFrame({'id': id_, 'answer': answer})","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:05:52.192815Z","iopub.execute_input":"2024-10-26T13:05:52.193264Z","iopub.status.idle":"2024-10-26T13:05:52.204252Z","shell.execute_reply.started":"2024-10-26T13:05:52.193227Z","shell.execute_reply":"2024-10-26T13:05:52.203582Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.aimo_2_inference_server.AIMO2InferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/ai-mathematical-olympiad-progress-prize-2/test.csv',\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-10-26T13:05:52.206051Z","iopub.execute_input":"2024-10-26T13:05:52.206544Z","iopub.status.idle":"2024-10-26T13:05:56.612209Z","shell.execute_reply.started":"2024-10-26T13:05:52.206514Z","shell.execute_reply":"2024-10-26T13:05:56.611364Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}