{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"},{"sourceId":10146472,"sourceType":"datasetVersion","datasetId":6263190}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission notebook for 2nd place solution in [UM - Game-Playing Strength of MCTS Variants](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants)\n\nLink to description: [2nd place solution](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants/discussion/549718)\n\nLink to model dataset, with instructions on how to reproduce the model binaries for the 2nd place solution (offline training): [um-gpsomctsv-2nd-place-solution](https://www.kaggle.com/datasets/fredrikupmark/um-gpsomctsv-2nd-place-solution)","metadata":{}},{"cell_type":"markdown","source":"The variable \"original_CV_optimized_prop\" below selects the desired blend between the two final submissions.\n\nA value of 0 reproduces the predictions of the 2nd place winning, more Public Leaderboard aligned, submission.\nThis submission scored 0.41996 on the private test set and reached nr 2 on the private leaderboard.\n\nA value of 1 reproduces the predictions of the second selected, more conservative, Cross Validation (CV) optimized submission.\nThis scored 0.42324 on the private test set. That is, this submission would have reached nr 6 on the Private Leaderboard (probably with Public Leaderboard aligned submissions ahead of it). Since this second submission was optimized to the larger CV data-set, it is possible (but definitely not certain) that blending values closer to 1 could generate predictions that generalize better outside the competition data.\n","metadata":{}},{"cell_type":"code","source":"original_CV_optimized_prop = 0  #0 => fully trust LB, 1 => fully trust CV","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_sets_to_use = list(range(6)) #Should be set to number of used seeds (i.e. 6 for the 2nd place solution)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:54:47.216095Z","iopub.execute_input":"2024-10-20T19:54:47.21641Z","iopub.status.idle":"2024-10-20T19:54:47.226223Z","shell.execute_reply.started":"2024-10-20T19:54:47.21637Z","shell.execute_reply":"2024-10-20T19:54:47.225311Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nr_of_gpus = 1 + (len(model_sets_to_use)>4)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:54:47.227811Z","iopub.execute_input":"2024-10-20T19:54:47.228122Z","iopub.status.idle":"2024-10-20T19:54:47.238132Z","shell.execute_reply.started":"2024-10-20T19:54:47.22809Z","shell.execute_reply":"2024-10-20T19:54:47.236685Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_paths = {}\ngpu_by_set = {}\nneural_model_paths = {}\ndata_paths[0] = f'/kaggle/input/um-gpsomctsv-2nd-place-solution/UM - Game-Playing Strength of MCTS Variants - 2nd place solution/models/models_SEED_{0}/'\nfor set_nr in model_sets_to_use:\n    data_paths[set_nr] = f'/kaggle/input/um-gpsomctsv-2nd-place-solution/UM - Game-Playing Strength of MCTS Variants - 2nd place solution/models/models_SEED_{set_nr}/'\n    gpu_by_set[set_nr] = set_nr%nr_of_gpus\n\n    neural_model_paths[set_nr] = f'/kaggle/input/um-gpsomctsv-2nd-place-solution/UM - Game-Playing Strength of MCTS Variants - 2nd place solution/models/models_SEED_{set_nr}/TENSORRT_PRE_MODEL'","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:55:19.347534Z","iopub.execute_input":"2024-10-20T19:55:19.347906Z","iopub.status.idle":"2024-10-20T19:55:19.353199Z","shell.execute_reply.started":"2024-10-20T19:55:19.34787Z","shell.execute_reply":"2024-10-20T19:55:19.352216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimport polars as pl\n\nimport numpy as np\n\nimport copy\n\nimport dill as pickle\n\nimport re\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-20T19:54:47.250049Z","iopub.execute_input":"2024-10-20T19:54:47.25094Z","iopub.status.idle":"2024-10-20T19:54:47.510555Z","shell.execute_reply.started":"2024-10-20T19:54:47.250896Z","shell.execute_reply":"2024-10-20T19:54:47.509679Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kaggle_evaluation.mcts_inference_server","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:54:47.512751Z","iopub.execute_input":"2024-10-20T19:54:47.513104Z","iopub.status.idle":"2024-10-20T19:54:48.082238Z","shell.execute_reply.started":"2024-10-20T19:54:47.513071Z","shell.execute_reply":"2024-10-20T19:54:48.081328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nprint(lgb.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:54:48.083444Z","iopub.execute_input":"2024-10-20T19:54:48.083965Z","iopub.status.idle":"2024-10-20T19:54:52.542345Z","shell.execute_reply.started":"2024-10-20T19:54:48.083917Z","shell.execute_reply":"2024-10-20T19:54:52.541374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import catboost\nfrom catboost import CatBoostRegressor\ncatboost.__version__","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:54:52.54363Z","iopub.execute_input":"2024-10-20T19:54:52.544598Z","iopub.status.idle":"2024-10-20T19:54:52.930003Z","shell.execute_reply.started":"2024-10-20T19:54:52.544561Z","shell.execute_reply":"2024-10-20T19:54:52.929044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:54:52.93117Z","iopub.execute_input":"2024-10-20T19:54:52.931483Z","iopub.status.idle":"2024-10-20T19:55:03.948656Z","shell.execute_reply.started":"2024-10-20T19:54:52.93145Z","shell.execute_reply":"2024-10-20T19:55:03.947851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow import saved_model","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:55:03.949822Z","iopub.execute_input":"2024-10-20T19:55:03.95049Z","iopub.status.idle":"2024-10-20T19:55:03.954802Z","shell.execute_reply.started":"2024-10-20T19:55:03.950455Z","shell.execute_reply":"2024-10-20T19:55:03.953727Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_agent_fields(df, agent_nr):\n    df = df.with_columns(\n\n        pl.col(f'agent{agent_nr}')\n\n        .str.splitn('-', len(agent_fields))\n\n        .struct.rename_fields(agent_fields)\n\n        .alias(\"fields\")\n\n    ).unnest(\"fields\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.097081Z","iopub.execute_input":"2024-10-11T20:00:01.098133Z","iopub.status.idle":"2024-10-11T20:00:01.10576Z","shell.execute_reply.started":"2024-10-11T20:00:01.098085Z","shell.execute_reply":"2024-10-11T20:00:01.104104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_agent_fields(df):\n    for agent_nr in [1,2]:\n        df = split_agent_fields(df, agent_nr)\n\n        for agent_field in agent_fields_to_init_dict:\n            for variable_sub_name in agent_fields_to_init_dict[agent_field]:\n                df = df.with_columns( pl.lit(df[agent_field]==variable_sub_name).alias(f'AG{agent_nr}_{agent_field}_{variable_sub_name}') )\n\n        df = df.drop(agent_fields)\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.108426Z","iopub.execute_input":"2024-10-11T20:00:01.109219Z","iopub.status.idle":"2024-10-11T20:00:01.126813Z","shell.execute_reply.started":"2024-10-11T20:00:01.109176Z","shell.execute_reply":"2024-10-11T20:00:01.125295Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cap_to_target_range(preds):\n    return np.maximum(-1, np.minimum(1, preds))","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.131591Z","iopub.execute_input":"2024-10-11T20:00:01.132078Z","iopub.status.idle":"2024-10-11T20:00:01.1392Z","shell.execute_reply.started":"2024-10-11T20:00:01.132033Z","shell.execute_reply":"2024-10-11T20:00:01.137734Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Thx to [https://www.kaggle.com/code/yunsuxiaozi/mcts-starter](https://www.kaggle.com/code/yunsuxiaozi/mcts-starter) for the idea to calculate text scores!","metadata":{}},{"cell_type":"code","source":"def ARI_McAlpine_EFLAW_CLRI(txt):\n    characters=len(txt)\n    words=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))\n    sentence=len(re.split('\\\\.|\\\\?|\\\\!',txt))\n    ari_score=4.71*(characters/words)+0.5*(words/sentence)-21.43\n    mcalpine_eflaw_score=(words+sentence*words)/sentence\n    L=100*characters/words\n    S=100*sentence/words\n    clri_score=0.0588*L-0.296*S-15.8\n    return ari_score, mcalpine_eflaw_score, clri_score","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.140972Z","iopub.execute_input":"2024-10-11T20:00:01.141427Z","iopub.status.idle":"2024-10-11T20:00:01.152675Z","shell.execute_reply.started":"2024-10-11T20:00:01.141382Z","shell.execute_reply":"2024-10-11T20:00:01.15134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_pd_col(pd_col):\n    pd_col=pd_col.fillna(\"nan\")\n    pd_col=pd_col.apply(lambda x:x.lower())\n    ps='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n    for p in ps:\n        pd_col=pd_col.apply(lambda x:x.replace(p,' '))\n    return np.array(pd_col)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.154231Z","iopub.execute_input":"2024-10-11T20:00:01.155938Z","iopub.status.idle":"2024-10-11T20:00:01.166418Z","shell.execute_reply.started":"2024-10-11T20:00:01.155891Z","shell.execute_reply":"2024-10-11T20:00:01.164786Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def drop_gamename(rule):\n    rule=rule[len('(game \"'):]\n    for i in range(len(rule)):\n        if rule[i]=='\"':\n            return rule[i+1:]","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.168349Z","iopub.execute_input":"2024-10-11T20:00:01.168963Z","iopub.status.idle":"2024-10-11T20:00:01.179593Z","shell.execute_reply.started":"2024-10-11T20:00:01.168905Z","shell.execute_reply":"2024-10-11T20:00:01.17795Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_player(rule):\n    player=''\n    stack=[]\n    for i in range(len(rule)):\n        player+=rule[i]\n        if rule[i] in ['(','{']:\n            stack.append(rule[i])\n        elif rule[i] in [')','}']:\n            stack=stack[:-1]\n            if len(stack)==0:\n                return player","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.181409Z","iopub.execute_input":"2024-10-11T20:00:01.183807Z","iopub.status.idle":"2024-10-11T20:00:01.197785Z","shell.execute_reply.started":"2024-10-11T20:00:01.183739Z","shell.execute_reply":"2024-10-11T20:00:01.196211Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_ARI_McAlpine_EFLAW_CLRI_col_scores(tmp_df, col_name, target_str_name):\n    cols_to_add = []\n    ARI_McAlpine_EFLAW_CLRI_values = tmp_df[col_name].to_pandas().apply(lambda x:ARI_McAlpine_EFLAW_CLRI(x))\n    ARI_McAlpine_EFLAW_CLRI_values = np.transpose(list(ARI_McAlpine_EFLAW_CLRI_values))\n    for iter_nr, calc_score in enumerate(['_ARI', '_McAlpine_EFLAW', '_CLRI']):\n        tmp_col_name = target_str_name+calc_score\n        cols_to_add.append(tmp_col_name)\n        tmp_df = tmp_df.with_columns( pl.lit( np.array( ARI_McAlpine_EFLAW_CLRI_values[iter_nr] ) ).alias(tmp_col_name) )    \n        \n    return tmp_df, cols_to_add","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.199563Z","iopub.execute_input":"2024-10-11T20:00:01.200015Z","iopub.status.idle":"2024-10-11T20:00:01.211238Z","shell.execute_reply.started":"2024-10-11T20:00:01.199971Z","shell.execute_reply":"2024-10-11T20:00:01.209915Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def LudRules(df, group_col, new_rules_col):\n    tmp_df = df.select(pl.col(group_col).value_counts()).unnest(group_col)\n    tmp_df = tmp_df.with_columns( pl.lit( np.array( tmp_df[group_col].to_pandas().apply(lambda x:drop_gamename(x)) ) ).alias(new_rules_col) )\n    tmp_df = tmp_df.with_columns( pl.lit( np.array( tmp_df[new_rules_col].to_pandas().apply(lambda rule:get_player(rule)) ) ).alias('player') )\n    tmp_df = tmp_df.with_columns( pl.lit( np.array( [rule[len(player):] for player,rule in zip(tmp_df['player'].to_pandas(),tmp_df[new_rules_col].to_pandas())] ) ).alias(new_rules_col) )\n\n    tmp_df, cols_to_add = get_ARI_McAlpine_EFLAW_CLRI_col_scores(tmp_df, new_rules_col, group_col)\n\n    df = tmp_df[[group_col, new_rules_col]+cols_to_add].join(\n        other = df,\n        on = group_col,\n        how = 'inner',\n        validate = '1:m',\n    )\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.238512Z","iopub.execute_input":"2024-10-11T20:00:01.239583Z","iopub.status.idle":"2024-10-11T20:00:01.253644Z","shell.execute_reply.started":"2024-10-11T20:00:01.239516Z","shell.execute_reply":"2024-10-11T20:00:01.252245Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(test: pl.DataFrame, sample_sub: pl.DataFrame):\n    # Replace this function with your inference code.\n    # You can return either a Pandas or Polars dataframe, though Polars is recommended.\n    # Each batch of predictions (except the very first) must be returned within 10 minutes of the batch features being provided.\n\n    \n    #load neural models (placed within predict function to comply with the server time limit)\n    if len(neural_models)==0:\n        for set_nr in model_sets_to_use:\n            with tf.device(f'/GPU:{gpu_by_set[set_nr]}'):\n                loaded_neural_models[set_nr] = saved_model.load(neural_model_paths[set_nr])\n                neural_models[set_nr] = loaded_neural_models[set_nr].signatures['serving_default']\n                \n    \n    group_col = 'LudRules'\n    test = LudRules(test, group_col, 'new_rules')\n    \n    test = test.with_columns( pl.lit( test['new_rules'] ).alias('LudRules') )\n    test = test.drop(['new_rules'])\n\n    \n    model_structure, agent_fields, agent_fields_to_init_dict, TARGET, FEATURES, group_FEATURES_cols = FEATURES_etc_by_set[0]\n\n    \n    for FEATURE in group_FEATURES_cols:\n        test = test.with_columns( pl.lit(False).alias(FEATURE) )\n\n    \n    \n    test_ext = copy.deepcopy(test)\n\n    test = test.with_columns( pl.lit(0).alias('is_ext_flipped') )\n    test_ext = test_ext.with_columns( pl.lit(1).alias('is_ext_flipped') )\n\n\n    test_ext = test_ext.with_columns( pl.lit(test['agent2']).alias('agent1') )\n    test_ext = test_ext.with_columns( pl.lit(test['agent1']).alias('agent2') )\n\n\n    #flip with 1-value\n    test_ext = test_ext.with_columns( pl.lit(1-test['AdvantageP1']).alias('AdvantageP1') )\n    \n\n    full_test_df = pl.concat([test, test_ext])\n    full_test_df = process_agent_fields(full_test_df)\n\n    len_test = len(test)\n\n    \n    n_threads = 2\n\n    \n    #NEURAL prep\n    test_neural = full_test_df\n    NRL_FEATURES_NORMALIZED = []\n    for FEATURE in NRL_FEATURES:\n        FEATURE_SHRT = FEATURE[4:]\n        if FEATURE in NRL_BOOL_FEATURES:\n            NRL_FEATURES_NORMALIZED.append(FEATURE_SHRT)\n        else:\n            NRL_FEATURES_NORMALIZED.append(FEATURE+'_NORMALIZED')\n            #per feature\n            normalized_feature = np.interp(test_neural[FEATURE_SHRT], ppf_tuples_COMPRESSED[FEATURE], norm_ppf_tuple_COMPRESSED)\n            test_neural = test_neural.with_columns( pl.lit(normalized_feature).alias(FEATURE+'_NORMALIZED') )\n\n    pred_data = np.array(test_neural[NRL_FEATURES_NORMALIZED]).astype('float32')    \n    \n\n    full_preds_overall = []\n    full_preds_overall_PubliLeaderboardFitted = []\n    \n    equal_w_preds_split_by_set = []\n    equal_w_preds_overall_by_set = []\n    equal_w_preds_reversed_split_by_set = []\n    equal_w_preds_reversed_overall_by_set = []\n\n\n    \n    \n    #predictions from BOOSTING models\n    \n    #catboost overall, unchanged model for all sets - only predict from first:\n    catboost_overall_pre_preds_essential = models_by_set[0]['catboost_essential']['overall'].predict(np.array(full_test_df[FEATURES+group_FEATURES_cols]), thread_count=n_threads)\n    catboost_overall_pre_preds = models_by_set[0]['catboost']['overall'].predict(np.array(full_test_df[FEATURES]), thread_count=n_threads)\n    \n    for set_nr in model_sets_to_use:\n        equal_w_preds_split_by_set.append([])\n        equal_w_preds_overall_by_set.append([])\n        equal_w_preds_reversed_split_by_set.append([])\n        equal_w_preds_reversed_overall_by_set.append([])\n        \n        preds_just_original = np.zeros(len_test)\n        preds = np.zeros(len_test)\n        preds_reversed_agents = np.zeros(len_test)\n        \n        model_structure, agent_fields, agent_fields_to_init_dict, TARGET, FEATURES, group_FEATURES_cols = FEATURES_etc_by_set[set_nr]\n    \n        for essential_add in ['', '_essential']:\n            if essential_add=='_essential':\n                pred_features = np.array(full_test_df[FEATURES+group_FEATURES_cols])\n            else:\n                pred_features = np.array(full_test_df[FEATURES])\n    \n            if essential_add=='_essential':\n                model_w_prop = model_structure['weighting_props']['essential']\n            else:\n                model_w_prop = (1-model_structure['weighting_props']['essential'])\n    \n            for model_name in model_structure['weighting_props']['model_types']:\n                model_w = model_structure['weighting_props']['model_types'][model_name]*model_w_prop\n    \n                model_structure_name = model_name+essential_add\n    \n                for cv_split_or_overall_switch in ['cv_splits', 'overall']:\n                    if cv_split_or_overall_switch == 'cv_splits':\n                        model_w_preds = model_w*(1-model_structure['weighting_props']['overall_models'])/nr_of_cv_splits\n    \n                        for split_model_nr in range(nr_of_cv_splits):\n                            if model_name == 'lgbm':\n                                pre_preds = models_by_set[set_nr][model_structure_name][cv_split_or_overall_switch][split_model_nr].predict(pred_features)\n                            elif model_name == 'catboost':\n                                pre_preds = models_by_set[set_nr][model_structure_name][cv_split_or_overall_switch][split_model_nr].predict(pred_features, thread_count=n_threads)\n    \n                            pre_preds = cap_to_target_range( pre_preds )\n    \n                            preds += pre_preds[:len_test] * model_w_preds\n                            preds_reversed_agents += pre_preds[len_test:] * model_w_preds\n\n                            if split_model_nr==0:\n                                equal_w_preds_split_by_set[-1].append(pre_preds[:len_test]/nr_of_cv_splits)\n                                equal_w_preds_reversed_split_by_set[-1].append(pre_preds[len_test:]*-1/nr_of_cv_splits)\n                            else:\n                                equal_w_preds_split_by_set[-1][-1] += pre_preds[:len_test]/nr_of_cv_splits\n                                equal_w_preds_reversed_split_by_set[-1][-1] += pre_preds[len_test:]*-1/nr_of_cv_splits\n    \n                    else: #i.e. overall model\n                        model_w_preds = model_w*model_structure['weighting_props']['overall_models']\n    \n                        if model_name == 'lgbm':\n                            pre_preds = models_by_set[set_nr][model_structure_name][cv_split_or_overall_switch].predict(pred_features)\n                        elif model_name == 'catboost':\n                            if essential_add=='_essential':\n                                pre_preds = catboost_overall_pre_preds_essential\n                            else:\n                                pre_preds = catboost_overall_pre_preds\n    \n                        pre_preds = cap_to_target_range( pre_preds )\n    \n                        preds += pre_preds[:len_test] * model_w_preds\n                        preds_reversed_agents += pre_preds[len_test:] * model_w_preds\n\n                        equal_w_preds_overall_by_set[-1].append(pre_preds[:len_test])\n                        equal_w_preds_reversed_overall_by_set[-1].append(pre_preds[len_test:]*-1)\n    \n        \n        pred_arrays = {}\n        pred_arrays['tmp_ens_preds'] = preds\n        pred_arrays['tmp_ens_preds_reversed_agents'] = preds_reversed_agents\n        pred_arrays['AdvantageP1'] = np.array(test['AdvantageP1'])\n\n\n        \n        #predictions from NEURAL models\n        with tf.device(f'/GPU:{gpu_by_set[set_nr]}'):\n            tmp_preds_NN = neural_models[set_nr](tf.convert_to_tensor(pred_data))['output_0'].numpy().T\n\n        \n        capped_preds = cap_to_target_range( tmp_preds_NN[0] )\n        tmp_preds = capped_preds * model_structure['weighting_props']['overall_models']\n        pred_arrays['preds_NEURAL'] = tmp_preds[:len_test]\n        pred_arrays['preds_reversed_agents_NEURAL'] = tmp_preds[len_test:]\n        equal_w_preds_split_by_set[-1].append(capped_preds[:len_test])\n        equal_w_preds_reversed_split_by_set[-1].append(capped_preds[len_test:]*-1)\n        \n        capped_preds = cap_to_target_range( tmp_preds_NN[3] )\n        tmp_preds = capped_preds * (1-model_structure['weighting_props']['overall_models'])\n        pred_arrays['preds_NEURAL'] += tmp_preds[:len_test]\n        pred_arrays['preds_reversed_agents_NEURAL'] += tmp_preds[len_test:]\n        equal_w_preds_overall_by_set[-1].append(capped_preds[:len_test])\n        equal_w_preds_reversed_overall_by_set[-1].append(capped_preds[len_test:]*-1)\n\n        \n        capped_preds = cap_to_target_range( tmp_preds_NN[1] )\n        tmp_preds = capped_preds * model_structure['weighting_props']['overall_models']\n        pred_arrays['preds_NEURAL_AE'] = tmp_preds[:len_test]\n        pred_arrays['preds_reversed_agents_NEURAL_AE'] = tmp_preds[len_test:]\n        equal_w_preds_split_by_set[-1].append(capped_preds[:len_test])\n        equal_w_preds_reversed_split_by_set[-1].append(capped_preds[len_test:]*-1)\n        \n        capped_preds = cap_to_target_range( tmp_preds_NN[4] )\n        tmp_preds = capped_preds * (1-model_structure['weighting_props']['overall_models'])\n        pred_arrays['preds_NEURAL_AE'] += tmp_preds[:len_test]\n        pred_arrays['preds_reversed_agents_NEURAL_AE'] += tmp_preds[len_test:]\n        equal_w_preds_overall_by_set[-1].append(capped_preds[:len_test])\n        equal_w_preds_reversed_overall_by_set[-1].append(capped_preds[len_test:]*-1)\n\n\n        capped_preds = cap_to_target_range( tmp_preds_NN[2] )\n        tmp_preds = capped_preds * model_structure['weighting_props']['overall_models']\n        pred_arrays['preds_NEURAL_BIG'] = tmp_preds[:len_test]\n        pred_arrays['preds_reversed_agents_NEURAL_BIG'] = tmp_preds[len_test:]\n        equal_w_preds_split_by_set[-1].append(capped_preds[:len_test])\n        equal_w_preds_reversed_split_by_set[-1].append(capped_preds[len_test:]*-1)\n        \n        capped_preds = cap_to_target_range( tmp_preds_NN[5] )\n        tmp_preds = capped_preds * (1-model_structure['weighting_props']['overall_models'])\n        pred_arrays['preds_NEURAL_BIG'] += tmp_preds[:len_test]\n        pred_arrays['preds_reversed_agents_NEURAL_BIG'] += tmp_preds[len_test:]\n        equal_w_preds_overall_by_set[-1].append(capped_preds[:len_test])\n        equal_w_preds_reversed_overall_by_set[-1].append(capped_preds[len_test:]*-1)\n        \n\n        #w/o full set of reversed agents\n        reg_params = model_structure['reg_params_neural']\n    \n        preds_final = np.zeros(len_test)\n        for param in reg_params.keys():\n            if param=='Intercept':\n                preds_final += reg_params[param]\n            else:\n                preds_final += reg_params[param] * pred_arrays[param]\n    \n        preds_final = cap_to_target_range( preds_final )\n        \n        reg_params = model_structure['reg_params_final_stretch']\n        preds_final_stretched = np.zeros(len_test)\n        for param in reg_params.keys():\n            if param=='Intercept':\n                preds_final_stretched += reg_params[param]\n            else:\n                preds_final_stretched += reg_params[param] * preds_final\n\n        preds_final_stretched = cap_to_target_range( preds_final_stretched )\n        \n        \n        #with full set of reversed agents\n        reg_params = model_structure['reg_params_neural_FULL']\n    \n        preds_final = np.zeros(len_test)\n        for param in reg_params.keys():\n            if param=='Intercept':\n                preds_final += reg_params[param]\n            else:\n                preds_final += reg_params[param] * pred_arrays[param]\n    \n        preds_final = cap_to_target_range( preds_final )\n        \n        reg_params = model_structure['reg_params_final_stretch_FULL']\n        preds_final_stretched_FULL = np.zeros(len_test)\n        for param in reg_params.keys():\n            if param=='Intercept':\n                preds_final_stretched_FULL += reg_params[param]\n            else:\n                preds_final_stretched_FULL += reg_params[param] * preds_final\n        \n        preds_final_stretched_FULL = cap_to_target_range( preds_final_stretched_FULL )\n\n        \n        \n        full_preds_overall.append( preds_final_stretched )\n        \n        full_set_of_reversed_agents_prop = -3.5 #(value fitted through public leaderboard)\n        full_preds_overall_PubliLeaderboardFitted.append( (1-full_set_of_reversed_agents_prop)*preds_final_stretched + full_set_of_reversed_agents_prop*preds_final_stretched_FULL )\n\n\n    #combine preds from all sets\n    median_prop = .75\n    full_preds_overall = (1-median_prop) * np.mean(full_preds_overall, axis=0) + median_prop * np.median(full_preds_overall, axis=0)\n    full_preds_overall_PubliLeaderboardFitted = (1-median_prop) * np.mean(full_preds_overall_PubliLeaderboardFitted, axis=0) + median_prop * np.median(full_preds_overall_PubliLeaderboardFitted, axis=0)\n\n    \n    #equal model weights preds\n    concatenated_eq_preds = np.concatenate( (equal_w_preds_split_by_set, equal_w_preds_overall_by_set, equal_w_preds_reversed_split_by_set, equal_w_preds_reversed_overall_by_set), axis=1)\n    concatenated_eq_preds = np.concatenate( concatenated_eq_preds, axis=0)\n    median_prop = .75\n    full_preds_overall_equal_w = (1-median_prop) * np.mean( concatenated_eq_preds, axis=0) + median_prop * np.median( concatenated_eq_preds, axis=0)\n    equal_w_prop = -.6 #(value fitted through public leaderboard)\n    full_preds_overall_PubliLeaderboardFitted = (1-equal_w_prop)*full_preds_overall_PubliLeaderboardFitted + equal_w_prop*full_preds_overall_equal_w\n\n    \n    #final blend of CV and PL optimized preds\n    full_preds_overall_final = original_CV_optimized_prop * full_preds_overall + (1-original_CV_optimized_prop) * full_preds_overall_PubliLeaderboardFitted\n\n    return sample_sub.with_columns(pl.Series('utility_agent1', cap_to_target_range(full_preds_overall_final) ))","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.255479Z","iopub.execute_input":"2024-10-11T20:00:01.255898Z","iopub.status.idle":"2024-10-11T20:00:01.313421Z","shell.execute_reply.started":"2024-10-11T20:00:01.25586Z","shell.execute_reply":"2024-10-11T20:00:01.311689Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(data_paths[0] + 'neural_objects.pkl', \"rb\") as f:\n    NRL_BOOL_FEATURES, NRL_FEATURES, NRL_FEATURES_NORMALIZED, norm_ppf_tuple_COMPRESSED, ppf_tuples_COMPRESSED = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.483939Z","iopub.execute_input":"2024-10-11T20:00:01.484369Z","iopub.status.idle":"2024-10-11T20:00:01.595225Z","shell.execute_reply.started":"2024-10-11T20:00:01.484328Z","shell.execute_reply":"2024-10-11T20:00:01.593591Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(data_paths[0] + 'model_structure_etc.pkl', \"rb\") as f:\n    model_structure, agent_fields, agent_fields_to_init_dict, TARGET, FEATURES, group_FEATURES_cols = pickle.load(f)   \n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:00:01.469934Z","iopub.execute_input":"2024-10-11T20:00:01.470366Z","iopub.status.idle":"2024-10-11T20:00:01.482116Z","shell.execute_reply.started":"2024-10-11T20:00:01.470323Z","shell.execute_reply":"2024-10-11T20:00:01.480516Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FEATURES_etc_by_set = {}\nfor set_nr in [0] + model_sets_to_use:\n    with open(data_paths[set_nr] + 'model_structure_etc.pkl', \"rb\") as f:\n        FEATURES_etc_by_set[set_nr] = pickle.load(f)   \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loaded_neural_models = {}\nneural_models = {}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nr_of_cv_splits = 5","metadata":{"execution":{"iopub.status.busy":"2024-10-05T17:17:35.388579Z","iopub.execute_input":"2024-10-05T17:17:35.388891Z","iopub.status.idle":"2024-10-05T17:17:35.393288Z","shell.execute_reply.started":"2024-10-05T17:17:35.38886Z","shell.execute_reply":"2024-10-05T17:17:35.392269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#load catboost and lgbm models\n\nuse_lgbm_early_stop = True\nif use_lgbm_early_stop:\n    early_stop_str_add = '_early_stop'\nelse:\n    early_stop_str_add = ''\n    \nuse_catboost_early_stop = True\n    \n\nmodels_by_set = {}\nfor set_nr in model_sets_to_use:\n    models_by_set[set_nr] = {}\n    for essential_add in ['', '_essential']:\n        for model_name in model_structure['weighting_props']['model_types']:\n            model_structure_name = model_name+essential_add\n            models_by_set[set_nr][model_structure_name] = {}\n            for cv_split_or_overall_switch in ['cv_splits', 'overall']:\n                if cv_split_or_overall_switch=='cv_splits':\n                    cat_cv_splits_best_iterations = []\n                    models_by_set[set_nr][model_structure_name][cv_split_or_overall_switch] = []\n                    for split_model_nr in range(nr_of_cv_splits):\n                        if model_name == 'lgbm':\n                            tmp_model = lgb.Booster(model_file=data_paths[set_nr] +f'{model_name}{essential_add}_sub_{split_model_nr}{early_stop_str_add}.txt')\n                        elif model_name == 'catboost':\n                            tmp_model = CatBoostRegressor()\n                            tmp_model.load_model(data_paths[set_nr] + f'{model_name}{essential_add}_sub_{split_model_nr}.cbm')\n                            if use_catboost_early_stop:\n                                best_iteration = tmp_model.get_best_iteration()\n                                print(f'caboost best_iteration split {split_model_nr}: {best_iteration}')\n                                cat_cv_splits_best_iterations.append(best_iteration)\n                                tmp_model.shrink(ntree_end=best_iteration)\n                        models_by_set[set_nr][model_structure_name][cv_split_or_overall_switch].append( tmp_model )\n                else: #i.e. overall model\n                    if model_name == 'lgbm':\n                        tmp_model = lgb.Booster(model_file=data_paths[set_nr]+f'{model_name}{essential_add}.txt')\n                        models_by_set[set_nr][model_structure_name][cv_split_or_overall_switch] = tmp_model\n                        \n                    elif model_name == 'catboost' and (set_nr==0 or 0 not in model_sets_to_use):\n                        tmp_model = CatBoostRegressor()\n                        tmp_model.load_model(data_paths[0] + f'{model_name}{essential_add}.cbm')\n                        if use_catboost_early_stop:\n                            best_iteration = 1 + round(.5*np.mean(np.asarray(cat_cv_splits_best_iterations)**.5)**2 + .5*np.median(cat_cv_splits_best_iterations))\n                            print(f'caboost \"best_iteration\" overall: {best_iteration}')\n                            tmp_model.shrink(ntree_end=best_iteration)\n                        if 0 not in models_by_set:\n                            models_by_set[0] = {}\n                        if model_structure_name not in models_by_set[0]:\n                            models_by_set[0][model_structure_name] = {}\n                        models_by_set[0][model_structure_name][cv_split_or_overall_switch] = tmp_model\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T17:17:35.403268Z","iopub.execute_input":"2024-10-05T17:17:35.403677Z","iopub.status.idle":"2024-10-05T17:17:41.618874Z","shell.execute_reply.started":"2024-10-05T17:17:35.403625Z","shell.execute_reply":"2024-10-05T17:17:41.617896Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:49:26.017617Z","iopub.execute_input":"2024-09-24T14:49:26.018035Z","iopub.status.idle":"2024-09-24T14:49:26.251586Z","shell.execute_reply.started":"2024-09-24T14:49:26.017992Z","shell.execute_reply":"2024-09-24T14:49:26.249639Z"},"trusted":true},"outputs":[],"execution_count":null}]}